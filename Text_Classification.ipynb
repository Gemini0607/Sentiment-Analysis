{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Polarity                                               Text\n",
      "0      pos  [\"films adapted comic books plenty success whe...\n",
      "1      pos  starters created alan moore eddie campbell bro...\n",
      "2      pos  say moore campbell thoroughly researched subje...\n",
      "3      pos  book graphic novel pages long includes nearly ...\n",
      "4      pos                        words dismiss film source .\n",
      "\n",
      "\n",
      "Length of Data: 59836 Files\n",
      "\n",
      "\n",
      "Number of Positive & Negative Labelled Data:\n",
      "pos    37484\n",
      "neg    22352\n",
      "Name: Polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Reading the Data\n",
    "df = pd.read_csv('out.csv', index_col = 0)\n",
    "print df.head()\n",
    "print '\\n'\n",
    "print 'Length of Data:',len(df),'Files'\n",
    "print '\\n'\n",
    "print 'Number of Positive & Negative Labelled Data:'\n",
    "print df.Polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mapping text labels to numeric labels, since classifiers cannot work with textual data \n",
    "df.Polarity = df.Polarity.map({'pos':1,'neg':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Training: (44877L,)\n",
      "X Testing: (14959L,)\n",
      "Y Training: (44877L,)\n",
      "Y Testing: (14959L,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into Train and Test sets\n",
    "# 'Text' is the independent variable and 'Polarity' is the dependent variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.Text, df.Polarity, test_size = 0.25, random_state = 10) \n",
    "print 'X Training:',(X_train.shape)\n",
    "print 'X Testing:',(X_test.shape)\n",
    "print 'Y Training:',(Y_train.shape)\n",
    "print 'Y Testing:',(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a Sparse Matrix of Term Frequency Identifiers and its Inverse Document Frequency of words in the dataset\n",
    "# The 'TfidfVectorizer' combines the functionality of 'CountVectorizer' and 'TfidfTransformer'\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(ngram_range = (1,1), analyzer=u'word')\n",
    "\n",
    "X_train_dtm = cv.fit_transform(X_train)\n",
    "X_test_dtm = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Creating Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Multinomial NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.776923591149\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb.fit(X_train_dtm, Y_train)\n",
    "mnb_predict = mnb.predict(X_test_dtm)\n",
    "\n",
    "print 'Accuracy:',mnb.score(X_test_dtm,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.827127481784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "\n",
    "LR.fit(X_train_dtm, Y_train)\n",
    "LR_predict = LR.predict(X_test_dtm)\n",
    "\n",
    "print 'Accuracy:',LR.score(X_test_dtm, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Stochastic Gradient Descent (SGD) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.795440871716\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "sgd_model = sgd.fit(X_train_dtm, Y_train)\n",
    "sgd_predict = sgd.predict(X_test_dtm)\n",
    "\n",
    "print 'Accuracy:',sgd.score(X_test_dtm, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Bernoulli's Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.845043117855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb_model = bnb.fit(X_train_dtm, Y_train)\n",
    "bnb_predict = bnb.predict(X_test_dtm)\n",
    "\n",
    "print 'Accuracy:',bnb.score(X_test_dtm, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.855605321211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "pac = PassiveAggressiveClassifier()\n",
    "\n",
    "pac_model = pac.fit(X_train_dtm, Y_train)\n",
    "pac_predict = pac.predict(X_test_dtm)\n",
    "\n",
    "print 'Accuracy:',pac.score(X_test_dtm, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Voting Classifier</h3>\n",
    "<i> A Voting Classifier allows you to implement multilpe classification models together without having to run each of them individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.834213516946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vclf = VotingClassifier(estimators=[('lr', LR), ('MultinomialNB', mnb), ('SGDClassifier', sgd),('BernoulliNB',bnb),('PassiveAggressiveClassifier',pac)], voting='hard')\n",
    "\n",
    "vclf.fit(X_train_dtm, Y_train)\n",
    "vclf.predict(X_test_dtm)\n",
    "\n",
    "print 'Accuracy:',vclf.score(X_test_dtm, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
